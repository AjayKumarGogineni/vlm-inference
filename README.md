**Objective**

Build and optimize a video summarization pipeline using an open-source model.
You will:

- Process a given set of videos.
- Generate concise and grounded textual summaries using an existing open-source model.
- Measure and record inference times for each component in the pipeline.
- Measure and record performance of the generated responses against ground truth responses
- Propose and implement optimizations to reduce total inference time.

**Dataset**

You will be provided with 270 TikTok videos in .mp4 format ([Google Drive](https://drive.google.com/drive/folders/1ZexqdCYpCQPpSjxL38Y8NpvPNCz_lJwH?usp=drive_link)) where the length varies from 5 seconds to 5 minutes. Your goal is to generate this information for each video using a Vision Language Model (VLM):

* Summary: A detailed and factual summary of the video content (no hallucinations).
* Category: One label selected from a predefined set of categories.

**Validation**

The generated responses should be compared against the ground truth responses to evaluate performance of summary and accuracy of category selection. The following metrics will be used for evaluating summary: BLEU, ROUGE and BERT score

**Baseline Model**

Use this open-source model for video summarization:

- SmolVLM2-2.2B-Instruct (https://huggingface.co/HuggingFaceTB/SmolVLM2-2.2B-Instruct, https://huggingface.co/blog/smolvlm2)

**Pipeline Requirements**

Your code should include the following components:

Steps with Description

1. Video Loading	   -    Load and read the videos
2. Audio Transcription - 	Extract and transcribe audio to text
3. Prompt Creation	 - 	  Generate the prompt in a format expected by the model
4. Text Generation	 -    Generate the textual summary and the video category by passing the prompt to the model
5. Post-processing	 -    Clean and format the model output. Compute and report the evaluation metrics against ground truth.

<img src="images/Pipeline_workflow.png" alt="Pipeline Workflow" width="600">

TikTok video frame example:

<img src="images/Video_frame.png" alt="Video Frame" width="200">

Audio Transcript example:

<img src="images/Audio_transcript.png" alt="Audio Transcript" width="600">

Ground Truth summary:
`The video is a travel vlog highlighting five unique activities to do on the Greek island of Paros. The presenter, speaking in a casual and enthusiastic tone, suggests: 1. Having a meal in Lefkes and hiking the Byzantine road to Prodromos, which takes about 45 minutes. 2. Visiting Kalogero beach for a natural mud mask, where one can use clay from the rocks. 3. Exploring Laggeri beach, described as secluded and a nudist beach, noting that there's enough space for everyone. 4. Visiting the Butterfly nature reserve, located 5 kilometers from Paros town, which can be reached via an organized excursion. 5. Driving by Agios Fokas, a place located 6 kilometers from the capital of Paros, featuring an unorganized yet picturesque church. The video concludes by asking viewers if they would like a part two and encouraging them to follow for daily Greece travel tips.`

Ground Truth Category:
`Travel & Events`

Generated Summary:
`The video showcases various activities and locations in the Greek island of Paros. It begins with a person standing in front of a scenic view of the sea and white buildings, with the text Paros 5 out of the box activities! displayed at the top. The person gestures and points towards the camera, indicating the start of the video. The scene transitions to a person in a red and white striped shirt standing in front of a picturesque white building with blue accents, with the text Could you do a vid on Paros please? üôè at the top.`

Generated Category:
`Travel & Events`

**Part A ‚Äî Baseline Measurement**

Implement the full pipeline using the baseline model.
Record execution time for:

- Video loading
- Audio transcription
- Text generation
- Total inference time

Save these measurements in a CSV file for analysis.

**Part B ‚Äî Optimization**

Apply at least two different optimization strategies to the baseline model to improve inference time and evaluation metrics.

- Sample key frames from the video and only pass them to the model.
- Model quantization (e.g., bitsandbytes, torch.quantization).
- Use model pruning or distillation.
- Use mixed precision (torch.float16).
- Batch processing of frames.
- Parallel data loading.
- Combination or any new techniques.

After applying optimizations, re-run timing tests and report improvements compared to the baseline.

**Deliverables**

- Code (.ipynb or .py)
- Timing report - CSV file recording inference times before and after optimization
- Short report (2‚Äì3 pages) covering:
  - Model choice and rationale
  - Baseline performance
  - Optimization techniques used
  - Trade-offs between speed and summary quality
  - Future improvements

**Steps to run the code**

1. Clone the repository to your local machine.
2. Create a virtual environment using Python 3.11.2 and activate it:
```bash
python3.11 -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
```
3. Install the required dependencies listed in requirements.txt by running the following command:
```bash
pip install -r requirements.txt
```
4. Download the dataset of TikTok videos and audio transcripts from the Google drive link ([Google Drive](https://drive.google.com/drive/folders/1ZexqdCYpCQPpSjxL38Y8NpvPNCz_lJwH?usp=drive_link))and place them in the `data/inputs/videos/` and `data/inputs/audio_transcripts/` directory respectively.
5. Update the paths in config.py to point to the correct input and output directories.
6. Run main.py to execute the video summarization pipeline. The pipeline processes each video sequentially, generates a summary and category for each video, and saves the results to a CSV file. It also records inference times and evaluation metrics.
```bash
python main.py
```
7. Sample output files can be found in the `data/outputs/` directory.

**Possible issues**

1. Ensure the paths in config.py are correctly set to your local directories.
2. Ensure to use Python 3.11.2 as some dependencies may not be compatible with other versions.